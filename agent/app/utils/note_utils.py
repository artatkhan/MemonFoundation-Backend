import os
import logging
import chromadb
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.core import StorageContext
from typing import Any, Tuple

def ensure_upload_dir_exists(uploaded_notes_dir: str):
    """Ensure the uploaded notes directory exists."""
    os.makedirs(uploaded_notes_dir, exist_ok=True)
    logging.info(f"Upload directory ensured: {uploaded_notes_dir}")

def setup_vector_store(tenant_id: str = None) -> Tuple[ChromaVectorStore, StorageContext]:
    """Set up Chroma vector store for storing embeddings."""
    logging.info("Setting up Chroma vector store.")
    # Create Chroma client
    chroma_client = chromadb.PersistentClient(path="./chroma_db")

    # Create collection with tenant-specific name
    collection_name = f"notes_{tenant_id}" if tenant_id else "notes"
    chroma_collection = chroma_client.get_or_create_collection(collection_name)

    # Create vector store
    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
    storage_context = StorageContext.from_defaults(vector_store=vector_store)
    return vector_store, storage_context

def format_modal_paper(response: Any, query: str) -> str:
    """
    Format the query response into a modal paper structure.

    Args:
        response: The query response from Llama Index
        query: The original query

    Returns:
        Formatted modal paper
    """
    modal_paper = f"MODAL PAPER\n"
    modal_paper += f"Query: {query}\n\n"
    modal_paper += f"Generated Content:\n"
    modal_paper += f"{'='*50}\n\n"

    if hasattr(response, 'response'):
        modal_paper += f"{response.response}\n\n"
    else:
        modal_paper += f"{str(response)}\n\n"

    modal_paper += f"{'='*50}\n"
    modal_paper += f"Generated by Tutor Agent\n"

    return modal_paper
